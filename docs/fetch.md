# Спецификация команды `fetch`

Этот документ описывает детальный, детерминированный и идемпотентный алгоритм выборки статей из источников.

Команда вызывается shortcut'ом "f" или строкой ":fetch" в режиме командной строки, результат должен отображаться на отдельном экране. UI должен выглядеть так:

1. Заголовок: Fetch (с отображением активных фильтров по source и topics, если есть; повторять формат вывода фильтров в заголовке Info Radar)
2. Progress bar, который отображает количество обрабатываемых статей
3. Поле вывода логов по операции (обрамлено зеленой рамкой)

Когда пользователь вызывает команду fetch, отображается соответствующий экран и команда сразу начинает выполняться. Можно отменить выполнение команды, нажав кнопку Esc. Выборка останавливается, но экран не закрывается, и пользователю в логах отображаются промежуточные результаты (с упоминанием о том, что fetch прерван пользователем). Повторный Esc прерывает выполнение команды и закрывает экран.

У каждого из источников должна быть собственная логика fetch (отедльные классы), которая возвращает экрану интерфейс с количеством статей для обновления и количеством уже обработанных статей, а также списком записей лога, которые будут отображаться в окне логов.

Если выбрано несколько источников или topic'ов в фильтре, то fetch должен быть запущен для каждого источника отдельно.

Предварительно должен идти этап подсчета количества страниц к обработке (см. алгоритм ниже). Progress bar при этом не определен и просто отображает длительную операцию. После того, как определены все статьи всех источников / топиков, команда начинает работу последовательно для каждого источника / топика.

Должна быть возможность "прокручивать" окно с логами командами j (вниз) и k (вверх). Строки лога должны выводиться в окно логов в режиме Live (см. rich.readthedocs.io/en/latest/live.html)

---

# 1. Цели алгоритма

Алгоритм `fetch` предназначен для:

1. Полного и надёжного **захвата всех новых статей** с сайта.
2. **Идемпотентности** — запуск может происходить многократно и в любой момент; повторные запуски должны корректно «догребать» статьи и обновлять данные.
3. **Обновления метаданных** существующих статей в пределах «окна актуальности».
4. **Никогда не перезаписывать содержимое статьи пустыми значениями** (если previously non-null → now null/empty → оставить старое значение).
5. Использования единственного жёсткого ограничителя: **`cutoff_date`**, который определяет нижнюю границу глубины обхода.
6. Умения формировать отчёт: какие статьи добавлены, какие обновлены, какие поля обновлены.

---

# 2. Конфигурация

Алгоритм использует два параметра:

### `cutoff_date`

* Жёсткая дата, ниже которой алгоритм **никогда не будет спускаться**.
* Пример: `2023-01-01`.

### `window_days`

* Размер окна актуальности для обновления метаданных.
* Пример: `30` дней.

### Произведённые параметры

* `now` — время запуска.
* `window_cutoff = now - window_days` — нижняя граница временного окна для обновления метаданных.

---

# 3. Основные определения

### Новая статья

Статья, отсутствующая в базе данных (определяется по нормализованному URL).

### Существующая статья

Статья, чей URL присутствует в базе.

### Метаданные

Поля, которые регулярно обновляются:

* количество просмотров
* количество комментариев
* рейтинг
* количество закладок
* теги
* автор
* заголовок
* первые абзацы (snippet)

### Полнотекстовое содержимое

Поле, содержащее полный текст статьи (опционально). Оно **никогда не переписывается пустым значением**.

---

# 4. Логические флаги выполнения

Перед запуском:

```
seen_existing = False
found_new_inside_window = False
```

* `seen_existing` — встречали ли мы известные статьи в текущем проходе.
* `found_new_inside_window` — были ли найдены новые статьи внутри окна актуальности.

---

# 5. Главный цикл

Алгоритм обходит сайт постранично. Количество страниц **не ограничено искусственно** — обход управляется только содержанием.

Для каждой страницы:

1. Получить список статей на странице, отсортированных по дате **от новых к старым**.
2. Для каждой статьи вызвать `process_item(item)`.
3. Остановить обход, если функция вернула сигнал `STOP`.

---

# 6. Функция `process_item(item)`

## 6.1. Предварительная нормализация

Перед обработкой для статьи нормализуются:

* дата публикации
* канонический URL
* заголовок
* метаданные

Если дата публикации отсутствует или невалидна — статья пропускается с логированием.

---

## 6.2. Обработка по дате

### Если `item.date < cutoff_date`

Это «слишком старая» статья.

#### Условия немедленной остановки алгоритма:

Остановить обход, если:

```
seen_existing == True
AND
found_new_inside_window == False
```

Это означает, что:

* окно актуальности исчерпано;
* новых статей внутри окна не было;
* всё, что ниже этой точки, устарело.

#### Если условия не выполнены — продолжаем

Например:

* пока не встретили существующие статьи (видим >0 новых);
* или если внутри окна были новые статьи (есть риск пропуска).

Возвращаем `CONTINUE`.

---

### Если `item.date >= cutoff_date`

Статья находится внутри области, которая обязана быть полностью обработана.

---

## 6.3. Проверка существования в базе

```
exists = db.contains(item.url)
```

---

## 6.4. Если статья **новая**

### Выполнить:

* вставить запись в БД со всеми доступными полями
* **не записывать null в любые поля** — отсутствие данных интерпретируется как «нет обновления»
* поля, которые отсутствуют в списке (например full_text) остаются в состоянии «not_fetched» или пустой строки
* добавить URL в список `added_articles`
* если `seen_existing == True`:

  * установить `found_new_inside_window = True`

Вернуть `CONTINUE`.

---

## 6.5. Если статья **существует**

Переходим в режим обновления.

### Установить:

```
seen_existing = True
```

### Обновления метаданных (diff)

Для каждого поля из списка метаданных:

1. Если поле присутствует в HTML и отличается от значения в БД → обновить.
2. Если поле **пустое/null в текущем fetch**, но было заполнено ранее → **не обновлять**.

Таким образом:

> **Переход из non-null → null невозможен.**

### Фиксация изменений

Если хотя бы одно поле изменено:

* добавить URL в `updated_articles`
* в `updated_fields_map[url]` записать:

```
field_name: (old_value → new_value)
```

Вернуть `CONTINUE`.

---

# 7. Условие остановки обхода страниц

Алгоритм завершает работу только при выполнении **одного из условий**:

### 1. Достигнута статья ниже cutoff_date

**и при этом** окно не содержит новых статей:

```
item.date < cutoff_date
AND
seen_existing == True
AND
found_new_inside_window == False
```

### 2. На странице отсутствуют статьи новее cutoff_date

(Редкий случай, сайт может показывать пустые страницы.)

### 3. Ошибка парсинга страницы, которую нельзя восстановить

(Должна логироваться, но не должна ломать идемпотентность.)

---

# 8. Идемпотентность

Алгоритм полностью идемпотентен за счёт:

1. Опоры только на **даты** и **состояние БД**, а не на внутренние флаги между запусками.
2. Отсутствия операций удаления.
3. Запрета перезаписывать значения null/empty в заполненные поля.
4. Всегда корректной обработки новых статей до `cutoff_date`.
5. Возможности повторить fetch после любой ошибки: алгоритм сам «догребёт» пропущенное.

---

# 9. Логирование результата

Каждый запуск `fetch` формирует отчёт:

### Список добавленных статей:

```
added_articles = [url1, url2, ...]
```

### Список обновлённых статей:

```
updated_articles = [urlA, urlB, ...]
```

### Карта изменённых полей:

```
updated_fields_map = {
  urlA: {
    "views": (120 → 140),
    "comments": (4 → 6)
  },
  urlB: {
    "rating": (7.1 → 7.5)
  }
}
```

### Метаданные запуска:

* `run_id`
* `started_at`
* `finished_at`
* `added_count`
* `updated_count`
* `errors_count`

---

# 10. Дополнительные требования к реализации

### 10.1. URL — это первичный ключ

Нормализованный URL однозначно идентифицирует статью.

### 10.2. Full-text обновляется отдельно

Если нужно скачивать полный текст — это должна быть отдельная команда или фоновая задача.

### 10.3. Поведение при пропаже полей на сайте

Если сайт перестал показывать поле (например, views), алгоритм **не затирает** его пустым значением.

### 10.4. Статья может обновляться автором

Если заметна корректировка snippet/title/tags:

* изменения перезаписываются, если значение в HTML не пустое.

### 10.5. Ошибки сети и парсинга

* должны логироваться
* не влияют на идемпотентность

---

# 11. Краткий псевдокод

```pseudo
init seen_existing = False
init found_new_inside_window = False

for each page:
    items = parse(page)

    for item in items:
        normalize(item)

        if item.date < cutoff_date:
            if seen_existing AND NOT found_new_inside_window:
                STOP
            else:
                CONTINUE

        exists = db.contains(item.url)

        if NOT exists:
            insert_non_null_fields(item)
            added_articles.append(item.url)
            if seen_existing:
                found_new_inside_window = True
            CONTINUE

        # exists == True
        seen_existing = True
        changes = diff_metadata(item, db[item.url])
        apply_changes_without_null_overwrite(changes)
        if changes:
            updated_articles.append(item.url)
            updated_fields_map[item.url] = changes
        CONTINUE
```

---

# 12. Ожидания от реализации

LLM, получившая эту спецификацию, должна реалистично реализовать:

* парсинг страниц
* корректное обновление БД
* защиту от null-overwrite
* идемпотентное поведение при повторных запусках
* точную логику остановки обхода
* подготовку отчёта о diff

---

# Конец спецификации
